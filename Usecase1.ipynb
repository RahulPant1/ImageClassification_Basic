{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import OpenCV module\n",
    "import cv2\n",
    "\n",
    "#import os module for reading training data directories and paths\n",
    "import os\n",
    "#import numpy to convert python lists to numpy arrays as \n",
    "#it is needed by OpenCV face recognizers\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(1)\n",
    "print(cam.isOpened())\n",
    "#print cam.grab()\n",
    "#cam.release()\n",
    "detector=cv2.CascadeClassifier('opencv-files/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter your id: 4\n"
     ]
    }
   ],
   "source": [
    "Id=raw_input('enter your id: ')\n",
    "sampleNum=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while(True):\n",
    "    ret, img = cam.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        \n",
    "        #incrementing sample number \n",
    "        sampleNum=sampleNum+1\n",
    "        #saving the captured face in the dataset folder\n",
    "        cv2.imwrite(\"dataSet/User.\"+Id +'.'+ str(sampleNum) + \".jpg\", gray[y:y+h,x:x+w]) #\n",
    "\n",
    "        cv2.imshow('frame',img)\n",
    "    #wait for 100 miliseconds \n",
    "    if cv2.waitKey(1000) & 0xFF == ord('q'):\n",
    "        break\n",
    "    # break if the sample number is morethan 20\n",
    "    elif sampleNum>20:\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "detector= cv2.CascadeClassifier(\"opencv-files/haarcascade_frontalface_default.xml\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getImagesAndLabels(path):\n",
    "    #get the path of all the files in the folder\n",
    "    imagePaths=[os.path.join(path,f) for f in os.listdir(path)] \n",
    "    #create empth face list\n",
    "    faceSamples=[]\n",
    "    #create empty ID list\n",
    "    Ids=[]\n",
    "    #now looping through all the image paths and loading the Ids and the images\n",
    "    for imagePath in imagePaths:\n",
    "        #loading the image and converting it to gray scale\n",
    "        pilImage=Image.open(imagePath).convert('L')\n",
    "        #Now we are converting the PIL image into numpy array\n",
    "        imageNp=np.array(pilImage,'uint8')\n",
    "        #getting the Id from the image\n",
    "        Id=int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "        # extract the face from the training image sample\n",
    "        faces=detector.detectMultiScale(imageNp)\n",
    "        #If a face is there then append that in the list as well as Id of it\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(imageNp[y:y+h,x:x+w])\n",
    "            Ids.append(Id)\n",
    "    return faceSamples,Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces,Ids = getImagesAndLabels('dataSet')\n",
    "recognizer.train(faces, np.array(Ids))\n",
    "recognizer.write('trainner/trainner.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('trainner/trainner.yml')\n",
    "cascadePath = \"opencv-files/haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascadePath);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "59.5731773025\n",
      "58.9923735355\n",
      "59.4594189694\n",
      "59.1676506436\n",
      "60.280930391\n",
      "61.850773151\n",
      "39.3769393553\n",
      "49.1488229425\n",
      "64.685438043\n",
      "49.6747478119\n",
      "65.5549022446\n",
      "43.3724764498\n",
      "63.0621924994\n",
      "55.389848271\n",
      "64.4037082305\n",
      "48.0092895116\n",
      "63.8920595111\n",
      "51.7177526994\n",
      "66.3347084002\n",
      "59.2865117415\n",
      "66.7218649439\n",
      "65.878437815\n",
      "63.7139023663\n",
      "65.2178139234\n",
      "102.410126963\n",
      "59.4992763766\n",
      "63.0521743443\n",
      "124.05321574\n",
      "63.9182506254\n",
      "55.0288015335\n",
      "108.141852861\n",
      "57.3557886167\n",
      "64.1463499976\n",
      "125.256393474\n",
      "64.3791896434\n",
      "65.0181465331\n",
      "61.2040844298\n",
      "128.850061993\n",
      "62.7498303096\n",
      "62.1921988167\n",
      "65.5581575479\n",
      "63.5548792623\n",
      "108.434028709\n",
      "65.8080485479\n",
      "107.041092095\n",
      "64.5953314349\n",
      "125.537832362\n",
      "129.941086568\n",
      "107.955150101\n",
      "107.65967837\n",
      "95.8744983276\n",
      "99.5997111927\n",
      "111.601331594\n",
      "64.9864598274\n",
      "110.95527808\n",
      "63.0731399524\n",
      "113.000554517\n",
      "109.969843798\n",
      "112.190510091\n",
      "66.1562920937\n",
      "119.155413583\n",
      "61.0348007784\n",
      "66.9300649769\n",
      "112.021824232\n",
      "66.5090088689\n",
      "112.030229405\n",
      "65.8677035482\n",
      "109.12323855\n",
      "65.0564350677\n",
      "100.810948981\n",
      "73.4828569246\n",
      "109.937998723\n",
      "100.084634458\n",
      "97.1927047348\n",
      "97.7184968934\n",
      "108.729497039\n",
      "121.432147734\n",
      "120.559041666\n",
      "112.426745708\n",
      "111.360339033\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cam = cv2.VideoCapture(1)\n",
    "print(cam.isOpened())\n",
    "\n",
    "fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "fontColor = (255, 0, 0)\n",
    "\n",
    "while True:\n",
    "    ret, im =cam.read()\n",
    "    gray=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    faces=faceCascade.detectMultiScale(gray, 1.2,5)\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),(225,0,0),2)\n",
    "        Id, conf = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        print conf\n",
    "        if(conf<60):\n",
    "            if(Id==1):\n",
    "                Id=\"Rahul\"\n",
    "            elif(Id==2):\n",
    "                Id=\"Kiddoo\"\n",
    "            elif(Id==3):\n",
    "                Id=\"Karthik\"\n",
    "        else:\n",
    "            Id=\"Unknown\"\n",
    "        cv2.putText(im,str(Id), (x,y+h),fontFace, fontScale, fontColor)\n",
    "    cv2.imshow('im',im) \n",
    "    if cv2.waitKey(1000) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cam.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
